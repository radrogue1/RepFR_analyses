{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmlreaders\n",
    "from cmlreaders import CMLReader, get_data_index \n",
    "import matplotlib.pyplot as plt \n",
    "import scipy as sp \n",
    "import xarray as xr\n",
    "from scipy import stats \n",
    "from scipy import spatial\n",
    "from scipy.stats import sem\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import os, csv, numpy, pandas\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import mne\n",
    "from mne import channels\n",
    "from mne import time_frequency\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import ptsa \n",
    "from ptsa.data.TimeSeriesX import TimeSeries \n",
    "from ptsa.data.readers import BaseEventReader\n",
    "\n",
    "\n",
    "%matplotlib inline \n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BEHAVIORAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data_index(kind = 'r1'); data = data[data['experiment'] == 'RepFR1']\n",
    "\n",
    "sample_evs = sample_reader.load('task_events')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R1501J',\n",
       " 'R1514E',\n",
       " 'R1516E',\n",
       " 'R1528E',\n",
       " 'R1531T',\n",
       " 'R1547D',\n",
       " 'R1556J',\n",
       " 'R1564J',\n",
       " 'R1568E']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rep_fr = data\n",
    "repfr_subs = list(rep_fr['subject'].unique())\n",
    "\n",
    "sessions = np.arange(0,10)\n",
    "repfr_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pullSubInfo(subject, session):\n",
    "    index = get_data_index(kind = 'r1')\n",
    "    reader = CMLReader(subject = str(subject), session = int(session), experiment = 'RepFR1')\n",
    "    evs = reader.load('task_events')\n",
    "    return evs \n",
    "\n",
    "def build_items(evs):\n",
    "    list_amount = np.arange(0,21)\n",
    "    ffr_list = 21\n",
    "    \n",
    "    rec_evs = evs[evs['type']=='REC_WORD'] #grab recall events \n",
    "    word_evs = evs[evs['type']=='WORD'] #word events\n",
    "    \n",
    "    word_pool = list(word_evs['item_name'].unique()) \n",
    "    total_word_number = len(word_pool)\n",
    "    \n",
    "    data_d= {'list_num':list_amount,\n",
    "          'ffr_list':ffr_list,\n",
    "          'wordpool':word_pool,\n",
    "          'total_words':total_word_number,\n",
    "          'rec_evs':rec_evs,\n",
    "          'word_evs':word_evs}\n",
    "\n",
    "    return data_d\n",
    "\n",
    "\n",
    "def Recall_A(data_d):\n",
    "    list_amount = data_d['list_num']\n",
    "    ffr_list = data_d['ffr_list']\n",
    "    word_pool = data_d['wordpool']\n",
    "    total_word_number = data_d['total_words']\n",
    "    rec_evs = data_d['rec_evs']\n",
    "    word_evs = data_d['word_evs']\n",
    "    \n",
    "    repeats = [1, 2, 3]\n",
    "    r1 = []\n",
    "    r2 = []\n",
    "    r3 = []\n",
    "    \n",
    "    all_recalls = []\n",
    "    for l in list_amount:\n",
    "        rep_d = {'1':[],\n",
    "                '2': [],\n",
    "                '3': []}\n",
    "        \n",
    "        d_list = word_evs[word_evs['list']==l]\n",
    "        rec_list = rec_evs[rec_evs['list']==l]\n",
    "\n",
    "        #c_recs = d_list[d_list['recalled']==True]\n",
    "\n",
    "\n",
    "        rec_words = rec_list['item_name'].unique()\n",
    "        all_recalls.extend(rec_words)\n",
    "\n",
    "\n",
    "        for r in repeats:\n",
    "\n",
    "            l_name = 'r'+str(r)\n",
    "            repeat_list = d_list[d_list['repeats']==r]\n",
    "\n",
    "            rep_d[str(r)] = repeat_list['item_name'].unique()\n",
    "\n",
    "        r1.extend(rep_d['1'])\n",
    "        r2.extend(rep_d['2'])\n",
    "        r3.extend(rep_d['3'])\n",
    "\n",
    "    prec = len(all_recalls)/total_word_number\n",
    "\n",
    "    rec1 = [a for a in all_recalls if a in r1]\n",
    "    rec2 = [a for a in all_recalls if a in r2]\n",
    "    rec3 = [a for a in all_recalls if a in r3]\n",
    "\n",
    "    prec_r1 = len(rec1)/len(r1)\n",
    "    prec_r2 = len(rec2)/len(r2)\n",
    "    prec_r3 = len(rec3)/len(r3)\n",
    "    \n",
    "    \n",
    "    num_r_words = [rec1, rec2, rec3]\n",
    "    prec_repeats = [prec, prec_r1, prec_r2, prec_r3]\n",
    "    \n",
    "    \n",
    "    d_ = {'words':num_r_words,\n",
    "         'probs': prec_repeats}\n",
    "    \n",
    "    return d_\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = []\n",
    "full_data = []\n",
    "# Put Subject Id Here\n",
    "subject = 'R1501J'\n",
    "for sess in sessions:\n",
    "    filter_c = False\n",
    "    try:\n",
    "        sub_info = pullSubInfo(subject, sess)\n",
    "        data_d = build_items(sub_info)\n",
    "        recall_data = Recall_A(data_d)\n",
    "\n",
    "\n",
    "        full_sd = ['Recall Rate (%)', sess,recall_data['probs'][0], recall_data['probs'][1], recall_data['probs'][2], recall_data['probs'][3]]\n",
    "        full_data.append(full_sd)\n",
    "        for value in recall_data['probs']:\n",
    "            if value <=0.50:\n",
    "                filter_c = True\n",
    "\n",
    "\n",
    "            else:\n",
    "                pass \n",
    "\n",
    "        if filter_c != True:\n",
    "\n",
    "            sub_ = [subject, sess,recall_data['probs'][0], recall_data['probs'][1], recall_data['probs'][2], recall_data['probs'][3]]\n",
    "            #print(sub_)\n",
    "            sub_data.append(sub_)\n",
    "\n",
    "\n",
    "            #sub_data.append(recall_data['probs'])\n",
    "        elif filter_c == True:\n",
    "            pass \n",
    "\n",
    "\n",
    "    except:\n",
    "        count=0\n",
    "\n",
    "\n",
    "all_data.extend(sub_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Recall Type</th>\n",
       "      <th>Recall Rate (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Total Recall</th>\n",
       "      <td>48.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep1</th>\n",
       "      <td>22.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep2</th>\n",
       "      <td>47.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rep3</th>\n",
       "      <td>65.87</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Recall Type   Recall Rate (%)\n",
       "Total Recall            48.76\n",
       "Rep1                    22.22\n",
       "Rep2                    47.09\n",
       "Rep3                    65.87"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df = pd.DataFrame(data = full_data, columns = ['Recall Type','session','Total Recall', 'Rep1','Rep2','Rep3'])\n",
    "\n",
    "sub_df = sub_df.groupby('Recall Type').mean().drop('session', axis = 1).round(4)*100\n",
    "sub_df = sub_df.transpose()\n",
    "sub_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'subject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3360\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-b0a70da39fb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msub_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_l\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msub_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'subject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3453\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3454\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3455\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3456\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3457\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/environmentname/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'subject'"
     ]
    }
   ],
   "source": [
    "sub_l = list(sub_df['subject'].unique())\n",
    "for s in sub_l:\n",
    "    print(sub_df[sub_df['subject']==s])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_events(subject, session):\n",
    "    reader = CMLReader(subject = subject, experiment = 'ltpRepFR', session = session)\n",
    "    return reader.load('task_events'), reader\n",
    "\n",
    "def generate_events(task_events):\n",
    "    task_events = task_events \n",
    "    \n",
    "    recall = task_events.query(\"type =='REC_WORD'\")\n",
    "    im_recall = recall[recall['list']!=26]\n",
    "    de_recall = recall[recall['list']==26]\n",
    "    \n",
    "    im_r = im_recall.to_records(index = False)\n",
    "    de_r = de_recall.to_records(index = False)\n",
    "    \n",
    "    return im_recall, de_recall, im_r, de_r \n",
    "\n",
    "def get_eeg(reader, subject, session, events, rel_start = 0, rel_stop = 500, filter_data = False):\n",
    "    rel_start = rel_start\n",
    "    rel_stop = rel_stop\n",
    "    \n",
    "    reader = reader\n",
    "    \n",
    "    eeg = reader.load_eeg(events = events, rel_start = rel_start, rel_stop = rel_stop, clean = False).to_mne()\n",
    "    \n",
    "    if filter_data == True:\n",
    "        eeg = eeg.filter(l_freq = 62., h_freq = 58., method = 'iir')\n",
    "        eeg = eeg.filter(l_freq = 122., h_freq = 118., method = 'iir')\n",
    "    \n",
    "    elif filter_data == False:\n",
    "        pass \n",
    "    \n",
    "    channels = eeg.ch_names\n",
    "    \n",
    "    return eeg, channels\n",
    "\n",
    "def get_powers(eeg, fmin, fmax, channels, event_record):\n",
    "    \n",
    "    power, fdone = mne.time_frequency.psd_multitaper(eeg, fmin = fmin, fmax = fmax, verbose = False)\n",
    "    \n",
    "    p = TimeSeries(power,\n",
    "                   dims = ('events', 'channels', 'frequency'),\n",
    "                   coords = {'events': event_record, 'channels': channels[:128], 'frequency': fdone, 'samplerate':0})\n",
    "                   \n",
    "                   \n",
    "                   \n",
    "                \n",
    "    \n",
    "    \n",
    "    return p, power, fdone\n",
    "\n",
    "\n",
    "def split_ROIs(power, sys):\n",
    "\n",
    "    mode = 8\n",
    "\n",
    "    if mode==8:\n",
    "        # by eight rois\n",
    "        ROI_list = ROI_LIST\n",
    "\n",
    "        power_byroi = []\n",
    "        for roi in ROI_list:\n",
    "            channels = ROIs[sys][roi]\n",
    "            x = power.sel(channels=np.in1d(power.channels.values, channels)).mean('channels')\n",
    "            power_byroi.append(x)\n",
    "\n",
    "        power_byroi = xr.concat(power_byroi, dim='ROIs')\n",
    "        power_byroi.coords['ROIs'] = ROI_list\n",
    "\n",
    "    elif mode==2:\n",
    "        # by front and back\n",
    "        ROI_list = ['anterior','posterior']\n",
    "\n",
    "        power_byroi = []\n",
    "        for roi in ROI_list:\n",
    "            if roi=='anterior':\n",
    "                channels = np.hstack((ROIs[sys]['LAS'],ROIs[sys]['LAI'],ROIs[sys]['RAS'],ROIs[sys]['RAI'])).tolist()\n",
    "            elif roi=='posterior':\n",
    "                channels = np.hstack((ROIs[sys]['LPS'],ROIs[sys]['LPI'],ROIs[sys]['RPS'],ROIs[sys]['RPI'])).tolist()\n",
    "            x = power.sel(channels=np.in1d(power.channels.values, channels)).mean('channels')\n",
    "            power_byroi.append(x)\n",
    "\n",
    "        power_byroi = xr.concat(power_byroi, dim='ROIs')\n",
    "        power_byroi.coords['ROIs'] = ROI_list\n",
    "\n",
    "    return power_byroi\n",
    "\n",
    "\n",
    "def power_by_roi(power, sys, log = True):\n",
    "    \n",
    "    power_split = split_ROIs(power, sys)\n",
    "    \n",
    "    if log == True:\n",
    "        power_split = np.log10(np.mean(power_split,1))\n",
    "\n",
    "    elif log == False:\n",
    "        pass \n",
    "    \n",
    "    \n",
    "    return power_split \n",
    "\n",
    "def plot_spectrum(power_data, plot_title, save_title, save = True):\n",
    "    ax = plt.subplot(111)\n",
    "    plt.imshow(power_data, interpolation = 'none', cmap = 'coolwarm', extent = [4, 128, 80, 0])\n",
    "    plt.ylabel('ROIs')\n",
    "    plt.xlabel('log frequency')\n",
    "    plt.title(plot_title)\n",
    "    ax.set_yticklabels(['LAI','RAI','LAS','RAS','LPI','RPI','LPS','RPS'])\n",
    "    ax.set_yticks([5, 15, 25, 35, 45, 55, 65, 75])\n",
    "    ax.set_xticks([4, 12,  20,  28,  36,  44,\n",
    "            52,  60,  68,  76,  84,  92, 100,\n",
    "           112, 124])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    if save == True:\n",
    "        plt.savefig('repfr_figs/'+str(save_title)+'.png')\n",
    "        \n",
    "    elif save == False:\n",
    "        pass \n",
    "    \n",
    "       \n",
    "    return\n",
    "    \n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects = ['LTP441, LTP442, LTP443, LTP444, LTP445, LTP446, LTP447']\n",
    "sessions = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "freqs= [  2.,   4.,   6.,   8.,  10.,  12.,  14.,  16.,  18.,  20.,  22.,\n",
    "        24.,  26.,  32.,  38.,  44.,  50.,  56.,  62.,  68.,  74.,  80.,\n",
    "        86.,  92.,  98., 104., 110., 116., 122., 128.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " #roi_text = ['LAI','RAI','LAS','RAS','LPI','RPI','LPS','RPS']\n",
    "ROI_LIST = ['LAS','LAI','LPS','LPI','RAS','RAI','RPS','RPI']\n",
    "ROIs = {'egi':{'LAS':['E12','E13','E19','E20','E24','E28','E29'],\n",
    "               'LAI':['E23','E26','E27','E33','E34','E39','E40'],\n",
    "               'LPS':['E37','E42','E52','E53','E54','E60','E61'],\n",
    "               'LPI':['E51','E58','E59','E64','E65','E66','E69'],\n",
    "               'RAS':['E4','E5','E111','E112','E117','E118','E124'],\n",
    "               'RAI':['E2','E3','E109','E115','E116','E122','E123'],\n",
    "               'RPS':['E78','E79','E85','E86','E87','E92','E93'],\n",
    "               'RPI':['E84','E89','E90','E91','E95','E96','E97']},\n",
    "        'biosemi':{'LAS':['C24','C25','D2','D3','D4','D11','D12','D13'],\n",
    "                   'LAI':['C31','C32','D5','D6','D9','D10','D21','D22'],\n",
    "                   'LPS':['D29','A5','A6','A7','A8','A17','A18'],\n",
    "                   'LPI':['D30','D31','A9','A10','A11','A15','A16'],\n",
    "                   'RAS':['B30','B31','B32','C2','C3','C4','C11','C12'],\n",
    "                   'RAI':['B24','B25','B28','B29','C5','C6','C9','C10'],\n",
    "                   'RPS':['A30','A31','A32','B3','B4','B5','B13'],\n",
    "                   'RPI':['A28','A29','B6','B7','B8','B11','B12']}}\n",
    "\n",
    "\n",
    "ROI_order = ['LAS', 'LAI', 'LPS', 'LPI', 'RAS', 'RAI', 'RPS', 'RPI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /protocols/ltp/subjects/LTP442/experiments/ltpRepFR/sessions/6/ephys/current_processed/LTP442_session_6.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9377791  =      0.000 ...  4579.000 secs...\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "Loading data for 304 events and 1025 original time points ...\n",
      "0 bad epochs dropped\n",
      "Not setting metadata\n",
      "Not setting metadata\n",
      "304 matching events found\n",
      "No baseline correction applied\n",
      "0 projection items activated\n",
      "0 bad epochs dropped\n",
      "Setting up band-stop filter from 58 - 62 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 58.00, 62.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Setting up band-stop filter from 1.2e+02 - 1.2e+02 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandstop zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 16 (effective, after forward-backward)\n",
      "- Cutoffs at 118.00, 122.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Extracting EDF parameters from /protocols/ltp/subjects/LTP442/experiments/ltpRepFR/sessions/6/ephys/current_processed/LTP442_session_6.bdf...\n",
      "BDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 9377791  =      0.000 ...  4579.000 secs...\n"
     ]
    }
   ],
   "source": [
    "sample_evs, evs_reader  = get_events('LTP442', 6)\n",
    "im_recall_o, de_recall_o, im_r, de_r = generate_events(sample_evs)\n",
    "\n",
    "im_recall, im_channels = get_eeg(evs_reader,'LTP442', 6, im_recall_o, filter_data = True)\n",
    "de_recall, de_channels = get_eeg(evs_reader,'LTP442', 6, de_recall_o, filter_data = True)\n",
    "#can condence this into one eeg function by creating a mask for all recall events before and during lsit 26 (EFR)\n",
    "\n",
    "im_p, im_power, fdone =  get_powers(im_recall, freqs[0], freqs[-1], im_channels, im_r)\n",
    "de_p, de_power, _ = get_powers(de_recall, freqs[0], freqs[-1], de_channels, de_r)\n",
    "\n",
    "im_split = power_by_roi(im_p, 'biosemi')\n",
    "de_split = power_by_roi(de_p, 'biosemi')\n",
    "\n",
    "difference = (im_split - de_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrum(difference, 'Delayed vs. Immediate Recall', 'LTP422.6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environmentname",
   "language": "python",
   "name": "environmentname"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
